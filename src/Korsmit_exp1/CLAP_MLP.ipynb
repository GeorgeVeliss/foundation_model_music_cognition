{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a260ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: change this to the path in your setup\n",
    "korsmit_exp1_path = \"../../data/Korsmit/Exp1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f635ffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgios/Documents/Google DeepMind Research Ready Programme 2025/foundation_model_music_cognition/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import ClapModel, AutoProcessor\n",
    "import torch\n",
    "import librosa\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6586ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLAP model + processor\n",
    "model = ClapModel.from_pretrained(\"laion/larger_clap_music\")\n",
    "processor = AutoProcessor.from_pretrained(\"laion/larger_clap_music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87de958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of CLAP's parameters: 193913882\n"
     ]
    }
   ],
   "source": [
    "print('total number of CLAP\\'s parameters:', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a16bd87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAP model size: 740.294MB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('CLAP model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df0e32",
   "metadata": {},
   "source": [
    "# Process audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b960e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stimuli = []\n",
    "stimuli_path = korsmit_exp1_path+\"Stimuli/\"\n",
    "\n",
    "for file in sorted(os.listdir(stimuli_path)):\n",
    "    if file.endswith(\".wav\"):\n",
    "        wav_path = os.path.join(stimuli_path, file)\n",
    "        audio, sample_rate = librosa.load(wav_path, sr=48000)\n",
    "        audio_stimuli.append(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dabe6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(audios=audio_stimuli, return_tensors=\"pt\", padding=True, sampling_rate=48000)\n",
    "audio_embeddings = model.get_audio_features(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71f03a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59, 512])\n"
     ]
    }
   ],
   "source": [
    "print(audio_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1aa71",
   "metadata": {},
   "source": [
    "# Process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f16d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I perceive this sound as happiness', 'I perceive this sound as sadness', 'I perceive this sound as anger', 'I perceive this sound as tenderness', 'I perceive this sound as fear']\n",
      "['This sound makes me feel happiness', 'This sound makes me feel sadness', 'This sound makes me feel anger', 'This sound makes me feel tenderness', 'This sound makes me feel fear']\n",
      "['I perceive this sound as positive', 'I perceive this sound as relaxed', 'I perceive this sound as awake']\n",
      "['This sound makes me feel positive', 'This sound makes me feel relaxed', 'This sound makes me feel awake']\n"
     ]
    }
   ],
   "source": [
    "discrete_tags = [\"happiness\", \"sadness\", \"anger\", \"tenderness\", \"fear\"]\n",
    "\n",
    "discrete_captions_perceived = [\"I perceive this sound as \" + tag for tag in discrete_tags]\n",
    "print(discrete_captions_perceived)\n",
    "discrete_captions_induced = [\"This sound makes me feel \" + tag for tag in discrete_tags]\n",
    "print(discrete_captions_induced)\n",
    "\n",
    "dimensional_tags = [\"positive\", \"relaxed\", \"awake\"]\n",
    "\n",
    "dimensional_captions_perceived = [\"I perceive this sound as \" + tag for tag in dimensional_tags]\n",
    "print(dimensional_captions_perceived)\n",
    "dimensional_captions_induced = [\"This sound makes me feel \" + tag for tag in dimensional_tags]\n",
    "print(dimensional_captions_induced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "032319cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = discrete_captions_perceived + discrete_captions_induced + dimensional_captions_perceived + dimensional_captions_induced\n",
    "\n",
    "# NOTE: currently using only dimensional_captions_induced\n",
    "tag_inputs = processor(text=dimensional_captions_induced, return_tensors=\"pt\", padding=True)\n",
    "tag_embeds = model.get_text_features(**tag_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a66c1",
   "metadata": {},
   "source": [
    "## Load csv files and extract related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8682ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master human responses DataFrame shape: (3835, 3)\n",
      "\n",
      "Master human responses (first 5 rows):\n",
      "      positive  relaxed  awake\n",
      "0         7.51     4.56   5.76\n",
      "1         2.96     2.87   3.29\n",
      "2         7.80     7.19   7.92\n",
      "3         6.14     7.67   5.46\n",
      "4         8.23     2.30   5.61\n",
      "...        ...      ...    ...\n",
      "3830      6.51     6.26   6.55\n",
      "3831      6.49     6.99   7.98\n",
      "3832      3.02     3.01   6.04\n",
      "3833      3.97     2.99   7.01\n",
      "3834      6.02     4.00   3.00\n",
      "\n",
      "[3835 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IDim_path = korsmit_exp1_path+\"Data/IDim/\"\n",
    "IDim_response_dfs = []\n",
    "\n",
    "for file in os.listdir(IDim_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(IDim_path, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=r'\\s*,\\s*', engine='python')\n",
    "            # Crucial: Strip whitespace from column names\n",
    "            df.columns = df.columns.str.strip()\n",
    "\n",
    "            # Ensure required rating columns exist\n",
    "            required_cols = ['positive', 'relaxed', 'awake']\n",
    "            if all(col in df.columns for col in required_cols):\n",
    "                # Select only the relevant columns and append to our list\n",
    "                IDim_response_dfs.append(df[required_cols])\n",
    "            else:\n",
    "                print(f\"Skipping file '{file_path}': Missing required columns ({required_cols}). Found columns: {df.columns.tolist()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading or processing file {file_path}: {e}\")\n",
    "\n",
    "\n",
    "# Concatenate all individual DataFrames into one master DataFrame for human responses\n",
    "if IDim_response_dfs:\n",
    "    master_human_responses_df = pd.concat(IDim_response_dfs, ignore_index=True)\n",
    "    print(f\"Master human responses DataFrame shape: {master_human_responses_df.shape}\\n\")\n",
    "    print(f\"Master human responses (first 5 rows):\\n{master_human_responses_df}\\n\")\n",
    "else:\n",
    "    raise ValueError(\"No valid CSV files found or processed in IDim_path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874063de",
   "metadata": {},
   "source": [
    "# Prepare features X and targets y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e862a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (features) after implicit alignment: (3835, 512)\n",
      "Shape of y (labels) after implicit alignment: (3835, 3)\n",
      "\n",
      "Training set size (X_train, y_train): (3068, 512), (3068, 3)\n",
      "Testing set size (X_test, y_test): (767, 512), (767, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_participants = len(IDim_response_dfs)\n",
    "if master_human_responses_df.shape[0] % len(audio_stimuli) != 0:\n",
    "    print(\"Warning: Total responses is not a perfect multiple of unique audio files. This might indicate inconsistent data or that not all participants rated all items, which could break implicit ordering.\")\n",
    "\n",
    "X_list = []\n",
    "for _ in range(num_participants):\n",
    "    X_list.extend(audio_embeddings.detach()) # Add a full set of embeddings for each participant\n",
    "\n",
    "# Convert to NumPy array\n",
    "X = np.array(X_list)\n",
    "\n",
    "# Extract y from the concatenated DataFrame\n",
    "y = master_human_responses_df[['positive', 'relaxed', 'awake']].values\n",
    "\n",
    "print(f\"Shape of X (features) after implicit alignment: {X.shape}\")\n",
    "print(f\"Shape of y (labels) after implicit alignment: {y.shape}\\n\")\n",
    "\n",
    "# Sanity check: X and y must have the same number of rows\n",
    "if X.shape[0] != y.shape[0]:\n",
    "    raise ValueError(\"Number of rows in X and y do not match after implicit alignment. This indicates an issue with the implicit ordering assumption or data loading.\")\n",
    "\n",
    "# --- Split Data into Training and Testing Sets ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size (X_train, y_train): {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set size (X_test, y_test): {X_test.shape}, {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df7405",
   "metadata": {},
   "source": [
    "# Train regression head (=MLP, a few projection layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a08bdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MLP Regressor training...\n",
      "Iteration 1, loss = 7.00666007\n",
      "Validation score: -0.361483\n",
      "Iteration 2, loss = 2.09906744\n",
      "Validation score: 0.087016\n",
      "Iteration 3, loss = 1.69112331\n",
      "Validation score: 0.151046\n",
      "Iteration 4, loss = 1.57831009\n",
      "Validation score: 0.188774\n",
      "Iteration 5, loss = 1.53475417\n",
      "Validation score: 0.204850\n",
      "Iteration 6, loss = 1.51081020\n",
      "Validation score: 0.196227\n",
      "Iteration 7, loss = 1.51017329\n",
      "Validation score: 0.212922\n",
      "Iteration 8, loss = 1.49618748\n",
      "Validation score: 0.213238\n",
      "Iteration 9, loss = 1.49536778\n",
      "Validation score: 0.205295\n",
      "Iteration 10, loss = 1.50386847\n",
      "Validation score: 0.210076\n",
      "Iteration 11, loss = 1.48700497\n",
      "Validation score: 0.197228\n",
      "Iteration 12, loss = 1.49916101\n",
      "Validation score: 0.219337\n",
      "Iteration 13, loss = 1.48584745\n",
      "Validation score: 0.207834\n",
      "Iteration 14, loss = 1.48256132\n",
      "Validation score: 0.224503\n",
      "Iteration 15, loss = 1.47626427\n",
      "Validation score: 0.214662\n",
      "Iteration 16, loss = 1.47791522\n",
      "Validation score: 0.215034\n",
      "Iteration 17, loss = 1.47911445\n",
      "Validation score: 0.211377\n",
      "Iteration 18, loss = 1.47391741\n",
      "Validation score: 0.217910\n",
      "Iteration 19, loss = 1.47959746\n",
      "Validation score: 0.204503\n",
      "Iteration 20, loss = 1.47425408\n",
      "Validation score: 0.198846\n",
      "Iteration 21, loss = 1.48375965\n",
      "Validation score: 0.210294\n",
      "Iteration 22, loss = 1.47736488\n",
      "Validation score: 0.226823\n",
      "Iteration 23, loss = 1.48500925\n",
      "Validation score: 0.223795\n",
      "Iteration 24, loss = 1.47501559\n",
      "Validation score: 0.221373\n",
      "Iteration 25, loss = 1.47062523\n",
      "Validation score: 0.229609\n",
      "Iteration 26, loss = 1.46570332\n",
      "Validation score: 0.220820\n",
      "Iteration 27, loss = 1.47414536\n",
      "Validation score: 0.230442\n",
      "Iteration 28, loss = 1.46421880\n",
      "Validation score: 0.218324\n",
      "Iteration 29, loss = 1.47233387\n",
      "Validation score: 0.219295\n",
      "Iteration 30, loss = 1.46747224\n",
      "Validation score: 0.223186\n",
      "Iteration 31, loss = 1.46703424\n",
      "Validation score: 0.226552\n",
      "Iteration 32, loss = 1.48396716\n",
      "Validation score: 0.212764\n",
      "Iteration 33, loss = 1.46829026\n",
      "Validation score: 0.216348\n",
      "Iteration 34, loss = 1.46370700\n",
      "Validation score: 0.219196\n",
      "Iteration 35, loss = 1.46750471\n",
      "Validation score: 0.215574\n",
      "Iteration 36, loss = 1.46933653\n",
      "Validation score: 0.238253\n",
      "Iteration 37, loss = 1.46645952\n",
      "Validation score: 0.209503\n",
      "Iteration 38, loss = 1.47349921\n",
      "Validation score: 0.216487\n",
      "Iteration 39, loss = 1.46592754\n",
      "Validation score: 0.240309\n",
      "Iteration 40, loss = 1.46674219\n",
      "Validation score: 0.221931\n",
      "Iteration 41, loss = 1.46482854\n",
      "Validation score: 0.213447\n",
      "Iteration 42, loss = 1.46495651\n",
      "Validation score: 0.210669\n",
      "Iteration 43, loss = 1.47098725\n",
      "Validation score: 0.223434\n",
      "Iteration 44, loss = 1.46157457\n",
      "Validation score: 0.216708\n",
      "Iteration 45, loss = 1.47319171\n",
      "Validation score: 0.221567\n",
      "Iteration 46, loss = 1.46574877\n",
      "Validation score: 0.221587\n",
      "Iteration 47, loss = 1.47029441\n",
      "Validation score: 0.218877\n",
      "Iteration 48, loss = 1.48283371\n",
      "Validation score: 0.202571\n",
      "Iteration 49, loss = 1.47565376\n",
      "Validation score: 0.220349\n",
      "Iteration 50, loss = 1.46100660\n",
      "Validation score: 0.223713\n",
      "Iteration 51, loss = 1.46738904\n",
      "Validation score: 0.223179\n",
      "Iteration 52, loss = 1.46703119\n",
      "Validation score: 0.217402\n",
      "Iteration 53, loss = 1.47177525\n",
      "Validation score: 0.215867\n",
      "Iteration 54, loss = 1.46685762\n",
      "Validation score: 0.219255\n",
      "Iteration 55, loss = 1.46111414\n",
      "Validation score: 0.218190\n",
      "Iteration 56, loss = 1.47508170\n",
      "Validation score: 0.224507\n",
      "Iteration 57, loss = 1.47405147\n",
      "Validation score: 0.215761\n",
      "Iteration 58, loss = 1.46493670\n",
      "Validation score: 0.202023\n",
      "Iteration 59, loss = 1.47034950\n",
      "Validation score: 0.216516\n",
      "Iteration 60, loss = 1.46371403\n",
      "Validation score: 0.233154\n",
      "Iteration 61, loss = 1.46947866\n",
      "Validation score: 0.205884\n",
      "Iteration 62, loss = 1.49274949\n",
      "Validation score: 0.209869\n",
      "Iteration 63, loss = 1.46988684\n",
      "Validation score: 0.229967\n",
      "Iteration 64, loss = 1.46494235\n",
      "Validation score: 0.218659\n",
      "Iteration 65, loss = 1.45712640\n",
      "Validation score: 0.225121\n",
      "Iteration 66, loss = 1.48216310\n",
      "Validation score: 0.224501\n",
      "Iteration 67, loss = 1.46373108\n",
      "Validation score: 0.225841\n",
      "Iteration 68, loss = 1.45690265\n",
      "Validation score: 0.232913\n",
      "Iteration 69, loss = 1.45486715\n",
      "Validation score: 0.210771\n",
      "Iteration 70, loss = 1.46904857\n",
      "Validation score: 0.220247\n",
      "Iteration 71, loss = 1.46965646\n",
      "Validation score: 0.224416\n",
      "Iteration 72, loss = 1.46976595\n",
      "Validation score: 0.222144\n",
      "Iteration 73, loss = 1.45891543\n",
      "Validation score: 0.216743\n",
      "Iteration 74, loss = 1.45534821\n",
      "Validation score: 0.217597\n",
      "Iteration 75, loss = 1.47075252\n",
      "Validation score: 0.214785\n",
      "Iteration 76, loss = 1.46310643\n",
      "Validation score: 0.228763\n",
      "Iteration 77, loss = 1.46504694\n",
      "Validation score: 0.217323\n",
      "Iteration 78, loss = 1.45546957\n",
      "Validation score: 0.213298\n",
      "Iteration 79, loss = 1.46411404\n",
      "Validation score: 0.226331\n",
      "Iteration 80, loss = 1.46008677\n",
      "Validation score: 0.226797\n",
      "Iteration 81, loss = 1.45562178\n",
      "Validation score: 0.211706\n",
      "Iteration 82, loss = 1.46010397\n",
      "Validation score: 0.217632\n",
      "Iteration 83, loss = 1.45701207\n",
      "Validation score: 0.222275\n",
      "Iteration 84, loss = 1.46339021\n",
      "Validation score: 0.226792\n",
      "Iteration 85, loss = 1.45974679\n",
      "Validation score: 0.217619\n",
      "Iteration 86, loss = 1.46707568\n",
      "Validation score: 0.211152\n",
      "Iteration 87, loss = 1.47405931\n",
      "Validation score: 0.192233\n",
      "Iteration 88, loss = 1.46265275\n",
      "Validation score: 0.214337\n",
      "Iteration 89, loss = 1.46234668\n",
      "Validation score: 0.225025\n",
      "Iteration 90, loss = 1.47504663\n",
      "Validation score: 0.219365\n",
      "Validation score did not improve more than tol=0.000100 for 50 consecutive epochs. Stopping.\n",
      "\n",
      "MLP Regressor training complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_regressor = MLPRegressor(\n",
    "    hidden_layer_sizes=(100, 50),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=50,\n",
    "    tol=1e-4\n",
    ")\n",
    "\n",
    "print(\"Starting MLP Regressor training...\")\n",
    "mlp_regressor.fit(X_train, y_train)\n",
    "print(\"\\nMLP Regressor training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6f9d9",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of predictions (y_pred): (767, 3)\n",
      "First 5 actual values (y_test):\n",
      "[[4.89 4.91 2.58]\n",
      " [7.01 6.27 6.6 ]\n",
      " [9.   8.02 8.03]\n",
      " [2.99 2.9  7.07]\n",
      " [6.08 6.32 4.61]]\n",
      "First 5 predicted values (y_pred):\n",
      "[[5.2952514 5.5431523 5.659073 ]\n",
      " [4.7216363 4.84595   4.8577704]\n",
      " [3.983328  3.0552099 6.7740064]\n",
      " [2.7067463 1.9613347 7.4050436]\n",
      " [4.927865  4.8070045 5.974429 ]]\n",
      "\n",
      "Mean Absolute Error (MAE): 1.4137\n",
      "Mean Absolute Percentage Error (MAPE): 41.39%\n",
      "\n",
      "Root Mean Squared Error (RMSE): 1.7607\n",
      "\n",
      "Pearson Correlation Coefficients (per dimension):\n",
      "  Positive Dimension: 0.5005\n",
      "  Relaxed Dimension: 0.5390\n",
      "  Awake Dimension: 0.2321\n",
      "  Average Pearson Correlation across dimensions: 0.4239\n",
      "\n",
      "R-squared scores:\n",
      "  valence = 0.24631647780467025\n",
      "  tension = 0.2843216159117342\n",
      "  energy = 0.03864955705908035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "y_pred = mlp_regressor.predict(X_test)\n",
    "\n",
    "print(f\"\\nShape of predictions (y_pred): {y_pred.shape}\")\n",
    "print(f\"First 5 actual values (y_test):\\n{y_test[:5]}\")\n",
    "print(f\"First 5 predicted values (y_pred):\\n{y_pred[:5]}\\n\")\n",
    "\n",
    "# Evaluation Metrics:\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE)\n",
    "absolute_percentage_error = np.abs((y_test - y_pred) / y_test) * 100\n",
    "mape = np.mean(absolute_percentage_error)\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\\n\")\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "# Pearson Correlation Coefficient (per dimension)\n",
    "print(\"\\nPearson Correlation Coefficients (per dimension):\")\n",
    "for i, dim_name in enumerate(['Positive', 'Relaxed', 'Awake']):\n",
    "    # Check for sufficient variance to calculate correlation\n",
    "    if np.std(y_test[:, i]) > 1e-6 and np.std(y_pred[:, i]) > 1e-6:\n",
    "        correlation, _ = pearsonr(y_test[:, i], y_pred[:, i])\n",
    "        print(f\"  {dim_name} Dimension: {correlation:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {dim_name} Dimension: Cannot calculate (insufficient variance in data for this dimension)\")\n",
    "\n",
    "correlations = []\n",
    "for i in range(y_test.shape[1]):\n",
    "    if np.std(y_test[:, i]) > 1e-6 and np.std(y_pred[:, i]) > 1e-6:\n",
    "        correlations.append(pearsonr(y_test[:, i], y_pred[:, i])[0])\n",
    "if correlations:\n",
    "    average_correlation = np.mean(correlations)\n",
    "    print(f\"  Average Pearson Correlation across dimensions: {average_correlation:.4f}\")\n",
    "else:\n",
    "    print(\"  No correlations could be calculated for averaging.\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# R-squared\n",
    "print(\"\\nR-squared scores:\")\n",
    "r2_valence = r2_score(y_test[:, 0], y_pred[:, 0])\n",
    "print(\"  valence =\", r2_valence)\n",
    "\n",
    "r2_tension = r2_score(y_test[:, 1], y_pred[:, 1])\n",
    "print(\"  tension =\", r2_tension)\n",
    "\n",
    "r2_energy = r2_score(y_test[:, 2], y_pred[:, 2])\n",
    "print(\"  energy =\", r2_energy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
