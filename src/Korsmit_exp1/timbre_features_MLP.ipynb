{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a260ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: change this to the path in your setup\n",
    "korsmit_exp1_path = \"../../data/Korsmit/Exp1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f635ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a66c1",
   "metadata": {},
   "source": [
    "## Load csv files and extract related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8682ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master human responses DataFrame shape: (3835, 4)\n",
      "\n",
      "Master human responses (first 5 rows):\n",
      "      positive  relaxed  awake  like\n",
      "0         3.68     3.78   4.42  3.41\n",
      "1         5.88     5.98   3.89  5.54\n",
      "2         6.53     5.59   6.59  6.17\n",
      "3         6.26     5.71   6.88  6.18\n",
      "4         2.80     2.62   5.15  1.87\n",
      "...        ...      ...    ...   ...\n",
      "3830      7.04     4.09   6.18  6.41\n",
      "3831      7.56     5.32   5.54  7.90\n",
      "3832      6.01     2.73   7.99  5.57\n",
      "3833      2.04     1.49   9.00  3.03\n",
      "3834      4.78     3.70   7.67  6.24\n",
      "\n",
      "[3835 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IDim_path = korsmit_exp1_path+\"Data/IDim/\"\n",
    "IDim_response_dfs = []\n",
    "\n",
    "for file in sorted(os.listdir(IDim_path)):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(IDim_path, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=r'\\s*,\\s*', engine='python')\n",
    "            # Crucial: Strip whitespace from column names\n",
    "            df.columns = df.columns.str.strip()\n",
    "\n",
    "            # Ensure required rating columns exist\n",
    "            required_cols = ['positive', 'relaxed', 'awake', 'like']\n",
    "            if all(col in df.columns for col in required_cols):\n",
    "                # Select only the relevant columns and append to our list\n",
    "                IDim_response_dfs.append(df[required_cols])\n",
    "            else:\n",
    "                print(f\"Skipping file '{file_path}': Missing required columns ({required_cols}). Found columns: {df.columns.tolist()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading or processing file {file_path}: {e}\")\n",
    "\n",
    "\n",
    "# Concatenate all individual DataFrames into one master DataFrame for human responses\n",
    "if IDim_response_dfs:\n",
    "    master_human_responses_df = pd.concat(IDim_response_dfs, ignore_index=True)\n",
    "    print(f\"Master human responses DataFrame shape: {master_human_responses_df.shape}\\n\")\n",
    "    print(f\"Master human responses (first 5 rows):\\n{master_human_responses_df}\\n\")\n",
    "else:\n",
    "    raise ValueError(\"No valid CSV files found or processed in IDim_path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc9a29f",
   "metadata": {},
   "source": [
    "# Extract precomputed timbre features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28038414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ppno', 'perceived/induced', 'dimensional/discrete', 'sequence',\n",
       "       'stimNo', 'stim',\n",
       "       'family (B = brass; W = woodwind; S = string; P = percussion)', 'instr',\n",
       "       'octave', 'nPlays', 'like', 'positive', 'relaxed', 'tense', 'awake',\n",
       "       'anger', 'fear', 'sadness', 'happiness', 'tenderness', 'IQR_Pitch',\n",
       "       'IQR_HarmonicSpectralDeviation', 'IQR_Tristimulus_1',\n",
       "       'IQR_Tristimulus_2', 'IQR_Tristimulus_3', 'IQR_HarmonicOddToEvenRatio',\n",
       "       'IQR_Inharmonicity', 'IQR_HarmonicEnergy', 'IQR_NoiseEnergy',\n",
       "       'IQR_Noisiness', 'IQR_HarmonicToNoiseEnergy',\n",
       "       'IQR_PartialsToNoiseEnergy', 'Median_Pitch',\n",
       "       'Median_HarmonicSpectralDeviation', 'Median_Tristimulus_1',\n",
       "       'Median_Tristimulus_2', 'Median_Tristimulus_3',\n",
       "       'Median_HarmonicOddToEvenRatio', 'Median_Inharmonicity',\n",
       "       'Median_HarmonicEnergy', 'Median_NoiseEnergy', 'Median_Noisiness',\n",
       "       'Median_HarmonicToNoiseEnergy', 'Median_PartialsToNoiseEnergy',\n",
       "       'IQR_SpectralCentroid', 'IQR_SpectralSpread', 'IQR_SpectralSkewness',\n",
       "       'IQR_SpectralKurtosis', 'IQR_SpectralFlatness', 'IQR_SpectralCrest',\n",
       "       'IQR_SpectralSlope', 'IQR_SpectralDecrease', 'IQR_SpectralRollOff',\n",
       "       'IQR_SpectralVariation', 'IQR_SpectralFlux', 'Median_SpectralCentroid',\n",
       "       'Median_SpectralSpread', 'Median_SpectralSkewness',\n",
       "       'Median_SpectralKurtosis', 'Median_SpectralFlatness',\n",
       "       'Median_SpectralCrest', 'Median_SpectralSlope',\n",
       "       'Median_SpectralDecrease', 'Median_SpectralRollOff',\n",
       "       'Median_SpectralVariation', 'Median_SpectralFlux', 'AttackTime',\n",
       "       'LogAttackTime', 'AttackSlope', 'DecreaseSlope', 'TemporalCentroid',\n",
       "       'EffectiveDuration', 'FrequencyOfEnergyModulation',\n",
       "       'AmplitudeOfEnergyModulation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to your timbre features CSV\n",
    "timbre_csv_path = korsmit_exp1_path+'Data/long_AT1_TimbreToolbox_220509.csv'\n",
    "\n",
    "# Load CSV\n",
    "timbre_df = pd.read_csv(timbre_csv_path)\n",
    "\n",
    "# Strip any extra whitespace from column names (good practice)\n",
    "timbre_df.columns = timbre_df.columns.str.strip()\n",
    "timbre_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5894e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'IQR_Pitch','IQR_HarmonicSpectralDeviation', 'IQR_Tristimulus_1',\n",
    "    'IQR_Tristimulus_2', 'IQR_Tristimulus_3', 'IQR_HarmonicOddToEvenRatio',\n",
    "    'IQR_Inharmonicity', 'IQR_HarmonicEnergy', 'IQR_NoiseEnergy',\n",
    "    'IQR_Noisiness', 'IQR_HarmonicToNoiseEnergy',\n",
    "    'IQR_PartialsToNoiseEnergy', 'Median_Pitch',\n",
    "    'Median_HarmonicSpectralDeviation', 'Median_Tristimulus_1',\n",
    "    'Median_Tristimulus_2', 'Median_Tristimulus_3',\n",
    "    'Median_HarmonicOddToEvenRatio', 'Median_Inharmonicity',\n",
    "    'Median_HarmonicEnergy', 'Median_NoiseEnergy', 'Median_Noisiness',\n",
    "    'Median_HarmonicToNoiseEnergy', 'Median_PartialsToNoiseEnergy',\n",
    "    'IQR_SpectralCentroid', 'IQR_SpectralSpread', 'IQR_SpectralSkewness',\n",
    "    'IQR_SpectralKurtosis', 'IQR_SpectralFlatness', 'IQR_SpectralCrest',\n",
    "    'IQR_SpectralSlope', 'IQR_SpectralDecrease', 'IQR_SpectralRollOff',\n",
    "    'IQR_SpectralVariation', 'IQR_SpectralFlux', 'Median_SpectralCentroid',\n",
    "    'Median_SpectralSpread', 'Median_SpectralSkewness',\n",
    "    'Median_SpectralKurtosis', 'Median_SpectralFlatness',\n",
    "    'Median_SpectralCrest', 'Median_SpectralSlope',\n",
    "    'Median_SpectralDecrease', 'Median_SpectralRollOff',\n",
    "    'Median_SpectralVariation', 'Median_SpectralFlux', 'AttackTime',\n",
    "    'LogAttackTime', 'AttackSlope', 'DecreaseSlope', 'TemporalCentroid',\n",
    "    'EffectiveDuration', 'FrequencyOfEnergyModulation',\n",
    "    'AmplitudeOfEnergyModulation'\n",
    "]\n",
    "\n",
    "# Limit timbre_df to the first 59 rows (59 sounds)\n",
    "X_base = timbre_df.loc[:58].sort_values('stimNo')[feature_names].values\n",
    "  # shape: (59, num_features)\n",
    "\n",
    "# Repeat each sound's features for all participants\n",
    "# Assume each participant rated all 59 sounds\n",
    "num_participants = int(master_human_responses_df.shape[0] / 59)\n",
    "\n",
    "X = np.tile(X_base, (num_participants, 1))  # shape: (3835, num_features)\n",
    "\n",
    "mask = np.isnan(X)\n",
    "\n",
    "X = np.where(mask, 0, X)\n",
    "\n",
    "y = master_human_responses_df[['positive', 'relaxed', 'awake', 'like']].values\n",
    "\n",
    "# Sanity check\n",
    "assert X.shape[0] == y.shape[0], \"Mismatch between feature and label rows!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874063de",
   "metadata": {},
   "source": [
    "# Prepare features X and targets y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e862a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size (X_train, y_train): (3451, 54), (3451, 4)\n",
      "Testing set size (X_test, y_test): (384, 54), (384, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Split Data into Training and Testing Sets ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size (X_train, y_train): {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set size (X_test, y_test): {X_test.shape}, {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df7405",
   "metadata": {},
   "source": [
    "# Train regression head (=MLP, a few projection layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a08bdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MLP Regressor training...\n",
      "Iteration 1, loss = 11.49583762\n",
      "Validation score: -3.030509\n",
      "Iteration 2, loss = 5.33952794\n",
      "Validation score: -0.418710\n",
      "Iteration 3, loss = 2.21825406\n",
      "Validation score: 0.051652\n",
      "Iteration 4, loss = 1.77615158\n",
      "Validation score: 0.155968\n",
      "Iteration 5, loss = 1.64255942\n",
      "Validation score: 0.201188\n",
      "Iteration 6, loss = 1.58921432\n",
      "Validation score: 0.218646\n",
      "Iteration 7, loss = 1.55623041\n",
      "Validation score: 0.230294\n",
      "Iteration 8, loss = 1.53539996\n",
      "Validation score: 0.235867\n",
      "Iteration 9, loss = 1.52523780\n",
      "Validation score: 0.242084\n",
      "Iteration 10, loss = 1.51357013\n",
      "Validation score: 0.244314\n",
      "Iteration 11, loss = 1.50619342\n",
      "Validation score: 0.248097\n",
      "Iteration 12, loss = 1.50127935\n",
      "Validation score: 0.248173\n",
      "Iteration 13, loss = 1.49555640\n",
      "Validation score: 0.251828\n",
      "Iteration 14, loss = 1.49252046\n",
      "Validation score: 0.251540\n",
      "Iteration 15, loss = 1.49128183\n",
      "Validation score: 0.250392\n",
      "Iteration 16, loss = 1.49449312\n",
      "Validation score: 0.250979\n",
      "Iteration 17, loss = 1.48964068\n",
      "Validation score: 0.254659\n",
      "Iteration 18, loss = 1.48998349\n",
      "Validation score: 0.249899\n",
      "Iteration 19, loss = 1.48360124\n",
      "Validation score: 0.256473\n",
      "Iteration 20, loss = 1.48107808\n",
      "Validation score: 0.254725\n",
      "Iteration 21, loss = 1.48214791\n",
      "Validation score: 0.256739\n",
      "Iteration 22, loss = 1.48073893\n",
      "Validation score: 0.255096\n",
      "Iteration 23, loss = 1.47797231\n",
      "Validation score: 0.255531\n",
      "Iteration 24, loss = 1.47934285\n",
      "Validation score: 0.257735\n",
      "Iteration 25, loss = 1.47743492\n",
      "Validation score: 0.253982\n",
      "Iteration 26, loss = 1.47536186\n",
      "Validation score: 0.255528\n",
      "Iteration 27, loss = 1.47652827\n",
      "Validation score: 0.257377\n",
      "Iteration 28, loss = 1.47599356\n",
      "Validation score: 0.254746\n",
      "Iteration 29, loss = 1.47728436\n",
      "Validation score: 0.256353\n",
      "Iteration 30, loss = 1.47590033\n",
      "Validation score: 0.256631\n",
      "Iteration 31, loss = 1.47305909\n",
      "Validation score: 0.257336\n",
      "Iteration 32, loss = 1.47367674\n",
      "Validation score: 0.256072\n",
      "Iteration 33, loss = 1.47672110\n",
      "Validation score: 0.257555\n",
      "Iteration 34, loss = 1.47396220\n",
      "Validation score: 0.258122\n",
      "Iteration 35, loss = 1.47391592\n",
      "Validation score: 0.253420\n",
      "Iteration 36, loss = 1.47326565\n",
      "Validation score: 0.255560\n",
      "Iteration 37, loss = 1.46918842\n",
      "Validation score: 0.256000\n",
      "Iteration 38, loss = 1.47284185\n",
      "Validation score: 0.256531\n",
      "Iteration 39, loss = 1.47387284\n",
      "Validation score: 0.257974\n",
      "Iteration 40, loss = 1.47429433\n",
      "Validation score: 0.256753\n",
      "Iteration 41, loss = 1.47696895\n",
      "Validation score: 0.255928\n",
      "Iteration 42, loss = 1.46888660\n",
      "Validation score: 0.256046\n",
      "Iteration 43, loss = 1.46986808\n",
      "Validation score: 0.252194\n",
      "Iteration 44, loss = 1.47126280\n",
      "Validation score: 0.257862\n",
      "Iteration 45, loss = 1.47044312\n",
      "Validation score: 0.258163\n",
      "Iteration 46, loss = 1.46924147\n",
      "Validation score: 0.256991\n",
      "Iteration 47, loss = 1.47168740\n",
      "Validation score: 0.257676\n",
      "Iteration 48, loss = 1.47482968\n",
      "Validation score: 0.257724\n",
      "Iteration 49, loss = 1.46962393\n",
      "Validation score: 0.253936\n",
      "Iteration 50, loss = 1.47150565\n",
      "Validation score: 0.256665\n",
      "Iteration 51, loss = 1.46962991\n",
      "Validation score: 0.250729\n",
      "Iteration 52, loss = 1.47030097\n",
      "Validation score: 0.254740\n",
      "Iteration 53, loss = 1.46730767\n",
      "Validation score: 0.255451\n",
      "Iteration 54, loss = 1.47039907\n",
      "Validation score: 0.257390\n",
      "Iteration 55, loss = 1.47124968\n",
      "Validation score: 0.251745\n",
      "Iteration 56, loss = 1.47146923\n",
      "Validation score: 0.257795\n",
      "Iteration 57, loss = 1.46804911\n",
      "Validation score: 0.253232\n",
      "Iteration 58, loss = 1.47093636\n",
      "Validation score: 0.251534\n",
      "Iteration 59, loss = 1.47067611\n",
      "Validation score: 0.255475\n",
      "Iteration 60, loss = 1.46701397\n",
      "Validation score: 0.255376\n",
      "Iteration 61, loss = 1.47022660\n",
      "Validation score: 0.257653\n",
      "Iteration 62, loss = 1.46895275\n",
      "Validation score: 0.251833\n",
      "Iteration 63, loss = 1.47275223\n",
      "Validation score: 0.255033\n",
      "Iteration 64, loss = 1.46950517\n",
      "Validation score: 0.253329\n",
      "Iteration 65, loss = 1.47149836\n",
      "Validation score: 0.256940\n",
      "Iteration 66, loss = 1.46929070\n",
      "Validation score: 0.255724\n",
      "Iteration 67, loss = 1.47030437\n",
      "Validation score: 0.253059\n",
      "Iteration 68, loss = 1.46686487\n",
      "Validation score: 0.255862\n",
      "Iteration 69, loss = 1.46867567\n",
      "Validation score: 0.249920\n",
      "Iteration 70, loss = 1.46698489\n",
      "Validation score: 0.253597\n",
      "Iteration 71, loss = 1.47355296\n",
      "Validation score: 0.257973\n",
      "Iteration 72, loss = 1.46847933\n",
      "Validation score: 0.254968\n",
      "Iteration 73, loss = 1.46848160\n",
      "Validation score: 0.248496\n",
      "Iteration 74, loss = 1.46721042\n",
      "Validation score: 0.258665\n",
      "Iteration 75, loss = 1.46527311\n",
      "Validation score: 0.253050\n",
      "Iteration 76, loss = 1.46807005\n",
      "Validation score: 0.256042\n",
      "Iteration 77, loss = 1.46701240\n",
      "Validation score: 0.252835\n",
      "Iteration 78, loss = 1.46620496\n",
      "Validation score: 0.256983\n",
      "Iteration 79, loss = 1.46596687\n",
      "Validation score: 0.253761\n",
      "Iteration 80, loss = 1.46658778\n",
      "Validation score: 0.255924\n",
      "Iteration 81, loss = 1.46713822\n",
      "Validation score: 0.250803\n",
      "Iteration 82, loss = 1.46764891\n",
      "Validation score: 0.255672\n",
      "Iteration 83, loss = 1.46804886\n",
      "Validation score: 0.253998\n",
      "Iteration 84, loss = 1.47031860\n",
      "Validation score: 0.252534\n",
      "Iteration 85, loss = 1.46438370\n",
      "Validation score: 0.252171\n",
      "Iteration 86, loss = 1.46926323\n",
      "Validation score: 0.251569\n",
      "Iteration 87, loss = 1.47044493\n",
      "Validation score: 0.251946\n",
      "Iteration 88, loss = 1.46934392\n",
      "Validation score: 0.251932\n",
      "Iteration 89, loss = 1.46772802\n",
      "Validation score: 0.253051\n",
      "Iteration 90, loss = 1.47023425\n",
      "Validation score: 0.253557\n",
      "Iteration 91, loss = 1.46876805\n",
      "Validation score: 0.251485\n",
      "Iteration 92, loss = 1.47050815\n",
      "Validation score: 0.253932\n",
      "Iteration 93, loss = 1.46643639\n",
      "Validation score: 0.256748\n",
      "Iteration 94, loss = 1.46607512\n",
      "Validation score: 0.252281\n",
      "Iteration 95, loss = 1.46881536\n",
      "Validation score: 0.254871\n",
      "Iteration 96, loss = 1.47001900\n",
      "Validation score: 0.253684\n",
      "Iteration 97, loss = 1.47410556\n",
      "Validation score: 0.242669\n",
      "Iteration 98, loss = 1.47120618\n",
      "Validation score: 0.255711\n",
      "Iteration 99, loss = 1.47256492\n",
      "Validation score: 0.250150\n",
      "Iteration 100, loss = 1.46776450\n",
      "Validation score: 0.257060\n",
      "Iteration 101, loss = 1.46935501\n",
      "Validation score: 0.250242\n",
      "Iteration 102, loss = 1.47342548\n",
      "Validation score: 0.248254\n",
      "Iteration 103, loss = 1.46738276\n",
      "Validation score: 0.253015\n",
      "Iteration 104, loss = 1.46759015\n",
      "Validation score: 0.252997\n",
      "Iteration 105, loss = 1.46639414\n",
      "Validation score: 0.253594\n",
      "Iteration 106, loss = 1.47161416\n",
      "Validation score: 0.253352\n",
      "Iteration 107, loss = 1.47386119\n",
      "Validation score: 0.243699\n",
      "Iteration 108, loss = 1.47051485\n",
      "Validation score: 0.254935\n",
      "Iteration 109, loss = 1.46794150\n",
      "Validation score: 0.244747\n",
      "Iteration 110, loss = 1.47444839\n",
      "Validation score: 0.253932\n",
      "Iteration 111, loss = 1.46692188\n",
      "Validation score: 0.250031\n",
      "Iteration 112, loss = 1.47220589\n",
      "Validation score: 0.253643\n",
      "Iteration 113, loss = 1.46858244\n",
      "Validation score: 0.248082\n",
      "Iteration 114, loss = 1.47503153\n",
      "Validation score: 0.245130\n",
      "Iteration 115, loss = 1.47167302\n",
      "Validation score: 0.251192\n",
      "Iteration 116, loss = 1.46888668\n",
      "Validation score: 0.252578\n",
      "Iteration 117, loss = 1.47238570\n",
      "Validation score: 0.253973\n",
      "Iteration 118, loss = 1.46680143\n",
      "Validation score: 0.252726\n",
      "Iteration 119, loss = 1.46567447\n",
      "Validation score: 0.253204\n",
      "Iteration 120, loss = 1.46927387\n",
      "Validation score: 0.251635\n",
      "Iteration 121, loss = 1.46902596\n",
      "Validation score: 0.255408\n",
      "Iteration 122, loss = 1.46841896\n",
      "Validation score: 0.255766\n",
      "Iteration 123, loss = 1.47153619\n",
      "Validation score: 0.255639\n",
      "Iteration 124, loss = 1.47588289\n",
      "Validation score: 0.256231\n",
      "Iteration 125, loss = 1.46657355\n",
      "Validation score: 0.249673\n",
      "Validation score did not improve more than tol=0.000100 for 50 consecutive epochs. Stopping.\n",
      "\n",
      "MLP Regressor training complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mlp_regressor = MLPRegressor(\n",
    "    hidden_layer_sizes=(100, 50),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=50,\n",
    "    tol=1e-4\n",
    ")\n",
    "\n",
    "# rf = RandomForestRegressor(n_estimators=5000)\n",
    "\n",
    "print(\"Starting MLP Regressor training...\")\n",
    "mlp_regressor.fit(X_train, y_train)\n",
    "print(\"\\nMLP Regressor training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6f9d9",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da11a895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.96, 8.32, 7.05, 8.  ],\n",
       "       [7.11, 7.01, 8.11, 7.01],\n",
       "       [4.68, 5.04, 5.88, 5.1 ],\n",
       "       ...,\n",
       "       [1.04, 1.  , 7.02, 1.98],\n",
       "       [8.72, 8.88, 8.84, 8.75],\n",
       "       [6.69, 4.62, 7.13, 6.38]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd51040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of predictions (y_pred): (384, 4)\n",
      "First 5 actual values (y_test):\n",
      "[[3.96 8.32 7.05 8.  ]\n",
      " [7.11 7.01 8.11 7.01]\n",
      " [4.68 5.04 5.88 5.1 ]\n",
      " [2.08 4.04 7.6  1.26]\n",
      " [6.34 6.43 5.32 4.8 ]]\n",
      "First 5 predicted values (y_pred):\n",
      "[[5.38915467 5.86170046 5.21601801 5.40391586]\n",
      " [4.69755393 4.96583829 4.85676618 4.91104396]\n",
      " [3.8179784  3.19733877 6.79529714 3.3575092 ]\n",
      " [2.81831699 2.20345215 6.95396629 2.25166629]\n",
      " [5.11046045 4.81583446 6.30417302 4.68668885]]\n",
      "\n",
      "Mean Absolute Error (MAE): 1.3833\n",
      "Mean Absolute Percentage Error (MAPE): 41.12%\n",
      "\n",
      "Root Mean Squared Error (RMSE): 1.7195\n",
      "\n",
      "Pearson Correlation Coefficients (per dimension):\n",
      "  positive Dimension: 0.5701\n",
      "  relaxed Dimension: 0.6171\n",
      "  awake Dimension: 0.3194\n",
      "  like Dimension: 0.5854\n",
      "Average Pearson Correlation across dimensions: 0.5230\n",
      "\n",
      "R-squared scores:\n",
      "  valence = 0.32209374473261776\n",
      "  tension = 0.37903183716006694\n",
      "  energy = 0.10141364495065741\n",
      "  like = 0.3415332670729845\n",
      "Average R-squared = 0.3415332670729845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "y_pred = mlp_regressor.predict(X_test)\n",
    "\n",
    "print(f\"\\nShape of predictions (y_pred): {y_pred.shape}\")\n",
    "print(f\"First 5 actual values (y_test):\\n{y_test[:5]}\")\n",
    "print(f\"First 5 predicted values (y_pred):\\n{y_pred[:5]}\\n\")\n",
    "\n",
    "# Evaluation Metrics:\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE)\n",
    "absolute_percentage_error = np.abs((y_test - y_pred) / y_test) * 100\n",
    "mape = np.mean(absolute_percentage_error)\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\\n\")\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "# Pearson Correlation Coefficient (per dimension)\n",
    "print(\"\\nPearson Correlation Coefficients (per dimension):\")\n",
    "for i, dim_name in enumerate(['positive', 'relaxed', 'awake', 'like']):\n",
    "    # Check for sufficient variance to calculate correlation\n",
    "    if np.std(y_test[:, i]) > 1e-6 and np.std(y_pred[:, i]) > 1e-6:\n",
    "        correlation, _ = pearsonr(y_test[:, i], y_pred[:, i])\n",
    "        print(f\"  {dim_name} Dimension: {correlation:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {dim_name} Dimension: Cannot calculate (insufficient variance in data for this dimension)\")\n",
    "\n",
    "correlations = []\n",
    "for i in range(y_test.shape[1]):\n",
    "    if np.std(y_test[:, i]) > 1e-6 and np.std(y_pred[:, i]) > 1e-6:\n",
    "        correlations.append(pearsonr(y_test[:, i], y_pred[:, i])[0])\n",
    "if correlations:\n",
    "    average_correlation = np.mean(correlations)\n",
    "    print(f\"Average Pearson Correlation across dimensions: {average_correlation:.4f}\")\n",
    "else:\n",
    "    print(\"  No correlations could be calculated for averaging.\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# R-squared\n",
    "print(\"\\nR-squared scores:\")\n",
    "r2_valence = r2_score(y_test[:, 0], y_pred[:, 0])\n",
    "print(\"  valence =\", r2_valence)\n",
    "\n",
    "r2_tension = r2_score(y_test[:, 1], y_pred[:, 1])\n",
    "print(\"  tension =\", r2_tension)\n",
    "\n",
    "r2_energy = r2_score(y_test[:, 2], y_pred[:, 2])\n",
    "print(\"  energy =\", r2_energy)\n",
    "\n",
    "r2_like = r2_score(y_test[:, 3], y_pred[:, 3])\n",
    "print(\"  like =\", r2_like)\n",
    "\n",
    "avg_r2 = r2_score(y_test, y_pred)\n",
    "print(\"Average R-squared =\", r2_like)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
